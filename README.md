# Sign-Language-Recognition-using-CNN

Abstract:

We have developed a method using neural networks to recognize finger spelling in 
American Sign Language in real time. Sign language is a natural and ancient form of communication, 
and our goal is to use computer vision techniques to automatically recognize hand gestures captured by a camera. 
To achieve this, we propose using a convolutional neural network (CNN) to analyze the position and orientation of 
the hand in an image. The CNN is trained and tested using data obtained from the hand's position and orientation. 
The hand is first processed through a filter, and then passed through a classifier 
that predicts the type of hand gesture. The images used to train the CNN are adjusted for accuracy.

Introduction:

American Sign Language is the main way of communication for the people who are deaf and dumb. 
Since they can't use spoken language, they rely on sign language to express themselves. 
Communication is how we share our thoughts and messages using different methods like speaking, signals, behavior, and visuals. 
Deaf and dumb people use their hands to make gestures and convey their ideas to others. These gestures are a form of nonverbal 
communication that relies on vision. It's known as sign language, and that's how deaf and dumb people communicate without using words.
